# üìä Dashboard de An√°lise de Vagas de Dados no Brasil

![Status do Projeto](https://img.shields.io/badge/status-ativo-brightgreen)
![Python](https://img.shields.io/badge/Python-3.13-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.35-ff4b4b.svg)

## üöÄ Vis√£o Geral do Projeto

Este projeto √© uma solu√ß√£o completa de an√°lise de dados que realiza web scraping di√°rio no portal Vagas.com para coletar oportunidades de "Analista de Dados" em todo o Brasil. Os dados coletados s√£o processados e apresentados em um dashboard interativo constru√≠do com Streamlit, que permite a visualiza√ß√£o de insights sobre o mercado de trabalho, como distribui√ß√£o de vagas por regi√£o, senioridade e tecnologias mais requisitadas.

---

### ‚ú® **[Acesse o Dashboard Ao Vivo](https://vagasad.streamlit.app/)** ‚ú®


---

## üéØ Principais Funcionalidades

* **Coleta de Dados Automatizada:** Um rob√¥ (scraper) desenvolvido com Python e Selenium visita o site Vagas.com diariamente.
* **Extra√ß√£o de Detalhes:** O scraper n√£o s√≥ coleta os dados principais, mas tamb√©m visita a p√°gina de cada vaga para extrair a descri√ß√£o completa, permitindo uma an√°lise de texto mais aprofundada.
* **Dashboard Interativo:** Uma interface amig√°vel constru√≠da com Streamlit permite que os usu√°rios filtrem os dados por UF, regi√£o e empresa.
* **An√°lises Relevantes:** O dashboard apresenta visualiza√ß√µes claras sobre:
  * Distribui√ß√£o de vagas por estado e cidade.
  * N√≠veis de senioridade mais demandados (J√∫nior, Pleno, S√™nior).
  * Tecnologias e ferramentas mais mencionadas nas descri√ß√µes das vagas.
* **Atualiza√ß√£o Di√°ria:** O processo √© 100% automatizado com GitHub Actions, garantindo que os dados estejam sempre atualizados.

## üõ†Ô∏è Tecnologias Utilizadas

Este projeto foi constru√≠do utilizando as seguintes tecnologias:

* **Linguagem:** Python 3.13
* **Web Scraping:** Selenium e BeautifulSoup4
* **An√°lise e Manipula√ß√£o de Dados:** Pandas
* **Dashboard e Visualiza√ß√£o:** Streamlit e Plotly Express
* **Automa√ß√£o (CI/CD):** GitHub Actions
* **Gerenciador de Pacotes:** UV

## ‚öôÔ∏è Como Funciona (Arquitetura)

O projeto opera em um ciclo di√°rio automatizado:

1. **Gatilho (Trigger):** Diariamente, um workflow do **GitHub Actions** √© acionado.
2. **Execu√ß√£o do Scraper:** A automa√ß√£o executa o script `scraper_vagas.py`.
3. **Coleta de Dados:** O script utiliza o **Selenium** para abrir o site Vagas.com, simular a a√ß√£o de clicar em "Carregar mais vagas" para expor todos os resultados e, em seguida, visita o link de cada vaga para extrair a descri√ß√£o completa.
4. **Armazenamento:** Os dados limpos e estruturados s√£o salvos em um arquivo `vagas_consolidadas.csv`.
5. **Commit Autom√°tico:** O GitHub Actions faz o commit e push do novo arquivo CSV para o reposit√≥rio.
6. **Visualiza√ß√£o:** O aplicativo **Streamlit** (`dashboard.py`), hospedado no Streamlit Community Cloud, l√™ o arquivo `vagas_consolidadas.csv` atualizado e exibe os dados no dashboard.

## üîß Configura√ß√£o e Instala√ß√£o Local

Para executar este projeto na sua m√°quina local, siga os passos abaixo.

**Pr√©-requisitos:**

* Python 3.10+
* [UV](https://github.com/astral-sh/uv) (gerenciador de pacotes) instalado.

**Passos:**

1. **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/rodineyw/analise_vagas.git
    cd analise_vagas
    ```

2. **Crie e ative o ambiente virtual:**

    ```bash
    uv v .venv
    source .venv/bin/activate  # No Windows, use: .venv\Scripts\activate
    ```

3. **Instale as depend√™ncias:**

    ```bash
    uv pip install -r requirements.txt
    ```

## ‚ñ∂Ô∏è Como Executar

Com o ambiente configurado, voc√™ pode rodar as duas partes do projeto:

1. **Para executar o scraper e coletar os dados mais recentes:**

    ```bash
    python scraper_vagas.py
    ```

    Aguarde a execu√ß√£o terminar. Um arquivo `vagas_consolidadas.csv` ser√° criado ou atualizado.

2. **Para visualizar o dashboard:**

    ```bash
    streamlit run dashboard.py
    ```

    O Streamlit iniciar√° um servidor local e abrir√° o dashboard no seu navegador.

## ‚úíÔ∏è Autor

* **R√≥diney W.** - *Consultor de Software & An√°lise de Dados*
* **LinkedIn:** [https://www.linkedin.com/in/rodineyw/](https://www.linkedin.com/in/rodineyw/)
* **GitHub:** [https://github.com/rodineyw](https://github.com/rodineyw)

*(Sinta-se √† vontade para adicionar seu email ou outras formas de contato)*

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
